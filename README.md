# Keras-and-Theano-layers-for-Switched-Pooling
  This is an implementation of the switched pooling layers first described in Zieler 2011 1. Switched pooling layers are a variation of the convolution max pooling layers that store both the max of the window as well as the location of the max. Additionally, switched unpooling layers use this max value and location to recreate the original image, an important step in producing convolutional autoencoders. These switch layers may also contain useful information about the movement of features within an image. The implementation is an extension of Theano's pooling layers 2 and contains unit tests as well as wrappers for modular neural network library Keras 3. Adding this functionality to these open source libraries will allow us to leverage Theano and Keras's research communities for testing and optimization.  1 M. D. Zeiler, G. W. Taylor and R. Fergus, "Adaptive deconvolutional networks for mid and high level feature learning," 2011 International Conference on Computer Vision, Barcelona, 2011, pp. 2018-2025.  2 Theano Development Team. "Theano: A Python framework for fast computation of mathematical expressions". http://deeplearning.net/software/theano/  3 Chollet, Francois, "Keras". https://github.com/fchollet/keras
